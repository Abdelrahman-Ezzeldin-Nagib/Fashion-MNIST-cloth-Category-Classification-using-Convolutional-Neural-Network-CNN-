{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from keras import datasets\n",
    "(x_train,y_train),(x_test,y_test) = datasets.mnist.load_data()\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "28"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "w = x_train.shape[1]\n",
    "h = x_train.shape[2]\n",
    "xtrain = []\n",
    "xtest = []\n",
    "ytrain = []\n",
    "ytest = []\n",
    "ind = 0\n",
    "for image in x_train:\n",
    "    #read images path\n",
    "    img = image\n",
    "    re = cv2.resize(img, (w,h))\n",
    "    xtrain.append(re)\n",
    "    ytrain.append(y_train[ind])\n",
    "    ind += 1\n",
    "\n",
    "#test = []\n",
    "ind = 0\n",
    "for image in x_test:\n",
    "    #read images path\n",
    "    img = image\n",
    "    re = cv2.resize(img, (w,h))\n",
    "    xtrain.append(re)\n",
    "    ytrain.append(y_train[ind])\n",
    "    ind += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "xtrain = np.array(xtrain)\n",
    "ytrain = np.array(ytrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(70000, 28, 28)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xtrain.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.utils import to_categorical\n",
    "ytrain = to_categorical(ytrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_rows = xtrain[0].shape[0]\n",
    "img_cols = xtrain[0].shape[1]\n",
    "xtrain = xtrain.reshape(xtrain.shape[0],img_rows,img_cols,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 26, 26, 64)        640       \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 13, 13, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 11, 11, 64)        36928     \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 7744)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 100)               774500    \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 10)                1010      \n",
      "=================================================================\n",
      "Total params: 813,078\n",
      "Trainable params: 813,078\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "2188/2188 [==============================] - 46s 21ms/step - loss: 0.9921 - acc: 0.8213\n",
      "Epoch 2/50\n",
      "2188/2188 [==============================] - 47s 22ms/step - loss: 0.7588 - acc: 0.8516\n",
      "Epoch 3/50\n",
      "2188/2188 [==============================] - 45s 21ms/step - loss: 0.7231 - acc: 0.8557\n",
      "Epoch 4/50\n",
      "2188/2188 [==============================] - 45s 21ms/step - loss: 0.6921 - acc: 0.8593 1s - loss: 0\n",
      "Epoch 5/50\n",
      "2188/2188 [==============================] - 45s 21ms/step - loss: 0.6532 - acc: 0.8621\n",
      "Epoch 6/50\n",
      "2188/2188 [==============================] - 45s 21ms/step - loss: 0.6024 - acc: 0.8660\n",
      "Epoch 7/50\n",
      "2188/2188 [==============================] - 45s 21ms/step - loss: 0.5463 - acc: 0.8721\n",
      "Epoch 8/50\n",
      "2188/2188 [==============================] - 45s 21ms/step - loss: 0.4860 - acc: 0.8820 2s - loss: 0.48 - ETA: 1s - loss: - ETA: 0s - loss: 0.4859 -\n",
      "Epoch 9/50\n",
      "2188/2188 [==============================] - 45s 21ms/step - loss: 0.4357 - acc: 0.8900 1\n",
      "Epoch 10/50\n",
      "2188/2188 [==============================] - 45s 20ms/step - loss: 0.3866 - acc: 0.8985\n",
      "Epoch 11/50\n",
      "2188/2188 [==============================] - 48s 22ms/step - loss: 0.3472 - acc: 0.9070\n",
      "Epoch 12/50\n",
      "2188/2188 [==============================] - 53s 24ms/step - loss: 0.3083 - acc: 0.9150\n",
      "Epoch 13/50\n",
      "2188/2188 [==============================] - 53s 24ms/step - loss: 0.2790 - acc: 0.9200\n",
      "Epoch 14/50\n",
      "2188/2188 [==============================] - 53s 24ms/step - loss: 0.2518 - acc: 0.9271\n",
      "Epoch 15/50\n",
      "2188/2188 [==============================] - 53s 24ms/step - loss: 0.2358 - acc: 0.9320\n",
      "Epoch 16/50\n",
      "2188/2188 [==============================] - 54s 25ms/step - loss: 0.2104 - acc: 0.9366\n",
      "Epoch 17/50\n",
      "2188/2188 [==============================] - 46s 21ms/step - loss: 0.2004 - acc: 0.9393\n",
      "Epoch 18/50\n",
      "2188/2188 [==============================] - 41s 19ms/step - loss: 0.1804 - acc: 0.9450\n",
      "Epoch 19/50\n",
      "2188/2188 [==============================] - 39s 18ms/step - loss: 0.1807 - acc: 0.9446\n",
      "Epoch 20/50\n",
      "2188/2188 [==============================] - 41s 19ms/step - loss: 0.1626 - acc: 0.9493\n",
      "Epoch 21/50\n",
      "2188/2188 [==============================] - 39s 18ms/step - loss: 0.1589 - acc: 0.9513\n",
      "Epoch 22/50\n",
      "2188/2188 [==============================] - 40s 18ms/step - loss: 0.1502 - acc: 0.9536 1s\n",
      "Epoch 23/50\n",
      "2188/2188 [==============================] - 41s 19ms/step - loss: 0.1416 - acc: 0.9566\n",
      "Epoch 24/50\n",
      "2188/2188 [==============================] - 39s 18ms/step - loss: 0.1427 - acc: 0.9565\n",
      "Epoch 25/50\n",
      "2188/2188 [==============================] - 39s 18ms/step - loss: 0.1417 - acc: 0.9571\n",
      "Epoch 26/50\n",
      "2188/2188 [==============================] - 39s 18ms/step - loss: 0.1291 - acc: 0.9606\n",
      "Epoch 27/50\n",
      "2188/2188 [==============================] - 38s 17ms/step - loss: 0.1180 - acc: 0.9637\n",
      "Epoch 28/50\n",
      "2188/2188 [==============================] - 39s 18ms/step - loss: 0.1295 - acc: 0.9611\n",
      "Epoch 29/50\n",
      "2188/2188 [==============================] - 39s 18ms/step - loss: 0.1201 - acc: 0.9634\n",
      "Epoch 30/50\n",
      "2188/2188 [==============================] - 38s 17ms/step - loss: 0.1187 - acc: 0.9633\n",
      "Epoch 31/50\n",
      "2188/2188 [==============================] - 38s 18ms/step - loss: 0.1139 - acc: 0.9652\n",
      "Epoch 32/50\n",
      "2188/2188 [==============================] - 38s 17ms/step - loss: 0.1047 - acc: 0.9681\n",
      "Epoch 33/50\n",
      "2188/2188 [==============================] - 38s 18ms/step - loss: 0.1120 - acc: 0.9659\n",
      "Epoch 34/50\n",
      "2188/2188 [==============================] - 39s 18ms/step - loss: 0.1152 - acc: 0.9666\n",
      "Epoch 35/50\n",
      "2188/2188 [==============================] - 38s 18ms/step - loss: 0.1022 - acc: 0.9701 1s - lo\n",
      "Epoch 36/50\n",
      "2188/2188 [==============================] - 39s 18ms/step - loss: 0.1023 - acc: 0.9699\n",
      "Epoch 37/50\n",
      "2188/2188 [==============================] - 39s 18ms/step - loss: 0.1023 - acc: 0.9698\n",
      "Epoch 38/50\n",
      "2188/2188 [==============================] - 40s 19ms/step - loss: 0.0980 - acc: 0.9715\n",
      "Epoch 39/50\n",
      "2188/2188 [==============================] - 40s 18ms/step - loss: 0.0970 - acc: 0.9713\n",
      "Epoch 40/50\n",
      "2188/2188 [==============================] - 40s 18ms/step - loss: 0.0973 - acc: 0.9726\n",
      "Epoch 41/50\n",
      "2188/2188 [==============================] - 40s 18ms/step - loss: 0.0962 - acc: 0.9725\n",
      "Epoch 42/50\n",
      "2188/2188 [==============================] - 41s 19ms/step - loss: 0.1045 - acc: 0.9718\n",
      "Epoch 43/50\n",
      "2188/2188 [==============================] - 39s 18ms/step - loss: 0.0966 - acc: 0.9729\n",
      "Epoch 44/50\n",
      "2188/2188 [==============================] - 41s 19ms/step - loss: 0.0885 - acc: 0.9741\n",
      "Epoch 45/50\n",
      "2188/2188 [==============================] - 42s 19ms/step - loss: 0.0903 - acc: 0.9742\n",
      "Epoch 46/50\n",
      "2188/2188 [==============================] - 41s 19ms/step - loss: 0.0913 - acc: 0.9750\n",
      "Epoch 47/50\n",
      "2188/2188 [==============================] - 41s 19ms/step - loss: 0.1007 - acc: 0.9729\n",
      "Epoch 48/50\n",
      "2188/2188 [==============================] - 41s 19ms/step - loss: 0.0926 - acc: 0.9751\n",
      "Epoch 49/50\n",
      "2188/2188 [==============================] - 40s 18ms/step - loss: 0.0937 - acc: 0.9749\n",
      "Epoch 50/50\n",
      "2188/2188 [==============================] - 42s 19ms/step - loss: 0.0900 - acc: 0.9762\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow.keras import layers, models\n",
    "\n",
    "model = models.Sequential()\n",
    "model.add(layers.Conv2D(64, (3, 3), activation='relu', input_shape=(xtrain.shape[1], xtrain.shape[2], 1) ))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(layers.Flatten())\n",
    "model.add(layers.Dense(100, activation='relu'))\n",
    "model.add(layers.Dense(10,activation='softmax'))\n",
    "model.summary()\n",
    "model.compile(optimizer='adam', loss=tf.keras.losses.categorical_crossentropy, metrics=['acc'])\n",
    "history = model.fit(xtrain, ytrain, batch_size= 32,epochs=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
